{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义超参数\n",
    "BATCH_SIZE=128\n",
    "DEVICE=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#cpu训练或者gpu训练\n",
    "EPOCHS=10#训练次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建pipeline,对图像处理\n",
    "pipeline=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下载，加载数据集\n",
    "from torch.utils.data import dataloader\n",
    "train_set=datasets.MNIST(\"data\",train=True,download=True,transform=pipeline)\n",
    "test_set=datasets.MNIST(\"data\",train=False,download=True,transform=pipeline)\n",
    "#加载数据\n",
    "train_loader=dataloader.DataLoader(train_set,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_loader=dataloader.DataLoader(test_set,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#插入代码，显示MNIST数据集的图片\n",
    "with open(\"./data/MNIST/raw/train-images-idx3-ubyte\",\"rb\") as f:\n",
    "    file=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image1=[int(str(item).encode('ascii'),16) for item in file[16:800]]\n",
    "# print(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# image1_np=np.array(image1,dtype=np.uint8).reshape(28,28,1)\n",
    "# print(image1_np.shape)\n",
    "\n",
    "# cv2.imwrite(\"digit.jpg\",image1_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建网络模型\n",
    "class Digit(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2d(1,10,5)#灰度图片通道， 输出通道，卷积核大小\n",
    "        self.conv2=nn.Conv2d(10,20,3)\n",
    "        self.fcl=nn.Linear(20*10*10,500)\n",
    "        self.fc2=nn.Linear(500,10)#输入通道，输出通道\n",
    "\n",
    "    def forward(self,x):\n",
    "        input_size=x.size(0)\n",
    "        x=self.conv1(x)\n",
    "        x=F.relu(x)\n",
    "        x=F.max_pool2d(x,2,2)\n",
    "\n",
    "        x=self.conv2(x)\n",
    "        x=F.relu(x)\n",
    "\n",
    "        x=x.view(input_size,-1)#数据降维\n",
    "\n",
    "        x=self.fcl(x)\n",
    "        x=F.relu(x)\n",
    "\n",
    "        x=self.fc2(x)\n",
    "\n",
    "        output=F.log_softmax(x,dim=1)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义优化器\n",
    "model=Digit().to(DEVICE)\n",
    "optimizer=optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练模型\n",
    "def train_model(model,device,train_loader,optimizer,epoch):\n",
    "    #训练模型\n",
    "    model.train()\n",
    "    for batch_index,(data,target) in enumerate(train_loader):\n",
    "        #将数据放到device上\n",
    "        data,target=data.to(device),target.to(device)\n",
    "        #梯度初始化为零\n",
    "        optimizer.zero_grad()\n",
    "        #训练后的结果\n",
    "        output=model(data)\n",
    "        #计算损失\n",
    "        loss=F.nll_loss(output,target)\n",
    "        #反向传播\n",
    "        loss.backward()\n",
    "        #更新参数\n",
    "        optimizer.step()\n",
    "        if batch_index%3000==0:\n",
    "            print(\"Train Epoch:{}[{}/{}({:.0f}%)]\\tLoss:{:.6f}\".format(\n",
    "                epoch,batch_index*len(data),len(train_loader.dataset),\n",
    "                100.*batch_index/len(train_loader),loss.item()\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义测试方法\n",
    "def test_model(model,device,test_loader):\n",
    "    #测试模型\n",
    "    model.eval()\n",
    "    #测试损失\n",
    "    test_loss=0\n",
    "    #正确率\n",
    "    correct=0\n",
    "    with torch.no_grad():#不进行梯度计算，也不进行反向传播\n",
    "        for data,target in test_loader:\n",
    "            #将数据放到device上\n",
    "            data,target=data.to(device),target.to(device)\n",
    "            output=model(data)\n",
    "            #计算损失\n",
    "            test_loss+=F.nll_loss(output,target,reduction=\"sum\").item()\n",
    "            pred=output.max(1,keepdim=True)[1]\n",
    "            #计算正确率 \n",
    "            correct+=pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss/=len(test_loader.dataset)\n",
    "    print(\"\\nTest set:Average loss:{:.4f},Accuracy:{}/{}({:.0f}%)\\n\".format(\n",
    "        test_loss,correct,len(test_loader.dataset),\n",
    "        100.*correct/len(test_loader.dataset)\n",
    "    ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:1[0/60000(0%)]\tLoss:2.301186\n",
      "\n",
      "Test set:Average loss:0.0673,Accuracy:9785/10000(98%)\n",
      "\n",
      "Train Epoch:2[0/60000(0%)]\tLoss:0.077185\n",
      "\n",
      "Test set:Average loss:0.0446,Accuracy:9853/10000(99%)\n",
      "\n",
      "Train Epoch:3[0/60000(0%)]\tLoss:0.038055\n",
      "\n",
      "Test set:Average loss:0.0385,Accuracy:9878/10000(99%)\n",
      "\n",
      "Train Epoch:4[0/60000(0%)]\tLoss:0.016030\n",
      "\n",
      "Test set:Average loss:0.0336,Accuracy:9886/10000(99%)\n",
      "\n",
      "Train Epoch:5[0/60000(0%)]\tLoss:0.036821\n",
      "\n",
      "Test set:Average loss:0.0310,Accuracy:9897/10000(99%)\n",
      "\n",
      "Train Epoch:6[0/60000(0%)]\tLoss:0.002908\n",
      "\n",
      "Test set:Average loss:0.0339,Accuracy:9885/10000(99%)\n",
      "\n",
      "Train Epoch:7[0/60000(0%)]\tLoss:0.029989\n",
      "\n",
      "Test set:Average loss:0.0407,Accuracy:9886/10000(99%)\n",
      "\n",
      "Train Epoch:8[0/60000(0%)]\tLoss:0.007170\n",
      "\n",
      "Test set:Average loss:0.0336,Accuracy:9904/10000(99%)\n",
      "\n",
      "Train Epoch:9[0/60000(0%)]\tLoss:0.005332\n",
      "\n",
      "Test set:Average loss:0.0383,Accuracy:9911/10000(99%)\n",
      "\n",
      "Train Epoch:10[0/60000(0%)]\tLoss:0.013055\n",
      "\n",
      "Test set:Average loss:0.0379,Accuracy:9910/10000(99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#调用模型输出方法\n",
    "for epoch in range(1,EPOCHS+1):\n",
    "    train_model(model,DEVICE,train_loader,optimizer,epoch)\n",
    "    test_model(model,DEVICE,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#保存训练参数\n",
    "torch.save(model.state_dict(), 'model_parameters.pth')\n",
    "#加载训练参数\n",
    "model.load_state_dict(torch.load('model_parameters.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
